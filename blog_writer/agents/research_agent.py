from langchain_google_genai import ChatGoogleGenerativeAI
from blog_writer.config import settings
from blog_writer.state import BlogState
from blog_writer.tools.tavily_search import deep_research
from typing import Dict


def create_research_agent():
    """Tavily ê²€ìƒ‰ + Gemini ìš”ì•½ ê¸°ë°˜ ì¡°ì‚¬ Agent"""

    llm = ChatGoogleGenerativeAI(
        model=settings.model_name,
        temperature=0.3,  # íŒ©íŠ¸ ê¸°ë°˜ ì¡°ì‚¬ëŠ” ë‚®ì€ ì˜¨ë„
        google_api_key=settings.google_api_key,
        max_retries=settings.max_retries
    )

    def research_node(state: BlogState) -> Dict:
        """ì£¼ì œì— ëŒ€í•œ ì‹¬ì¸µ ì¡°ì‚¬ ìˆ˜í–‰"""
        topic = state["topic"]
        keywords = state.get("keywords", [])

        print(f"ğŸ” ì£¼ì œ ì¡°ì‚¬ ì¤‘: {topic}")

        # 1. ë©”ì¸ ì£¼ì œ ê²€ìƒ‰
        main_query = f"{topic} ìµœì‹  ì •ë³´ 2025"
        main_results = deep_research.invoke({"query": main_query})

        # 2. ê° í‚¤ì›Œë“œë³„ ê²€ìƒ‰
        keyword_results = []
        for keyword in keywords:
            query = f"{topic} {keyword} ìƒì„¸ ì •ë³´"
            results = deep_research.invoke({"query": query})
            keyword_results.append({
                "keyword": keyword,
                "results": results
            })

        # 3. ê²€ìƒ‰ ê²°ê³¼ í†µí•©
        all_search_data = f"""# ë©”ì¸ ì¡°ì‚¬ ê²°ê³¼

**ì¿¼ë¦¬**: {main_query}
**ìš”ì•½**: {main_results.get('answer', 'N/A')}

## ìƒì„¸ ê²°ê³¼

"""
        for i, result in enumerate(main_results.get('results', []), 1):
            all_search_data += f"""
### {i}. {result['title']}
- **ì¶œì²˜**: {result['url']}
- **ê´€ë ¨ë„**: {result.get('score', 0):.2f}

{result['content']}

---
"""

        # í‚¤ì›Œë“œë³„ ê²°ê³¼ ì¶”ê°€
        for kw_data in keyword_results:
            kw = kw_data['keyword']
            kw_results = kw_data['results']
            all_search_data += f"\n# í‚¤ì›Œë“œ ì¡°ì‚¬: {kw}\n\n"
            all_search_data += f"**ìš”ì•½**: {kw_results.get('answer', 'N/A')}\n\n"

        # 4. ğŸ†• Clarification ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        clarification_context = ""
        if "clarifications" in state and state.get("clarifications"):
            clarifications = state["clarifications"]
            if "research" in clarifications:
                research_clarif = clarifications["research"]
                # Reconstruct ClarificationResponse to use to_prompt_context
                from blog_writer.models.clarification import ClarificationResponse, ClarificationQuestion
                from datetime import datetime

                clarif_obj = ClarificationResponse(
                    questions=[ClarificationQuestion(**q) for q in research_clarif["questions"]],
                    answers=research_clarif["answers"],
                    skipped=research_clarif["skipped"],
                    timestamp=datetime.fromisoformat(research_clarif["timestamp"]),
                    stage=research_clarif["stage"]
                )
                clarification_context = clarif_obj.to_prompt_context()

        # 5. LLMìœ¼ë¡œ ì¢…í•© ì •ë¦¬
        synthesis_prompt = f"""ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ê¸° ìœ„í•œ ì¡°ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ "{topic}"ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ ì‘ì„±ì„ ìœ„í•œ ì¢…í•© ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

{clarification_context}

## ê²€ìƒ‰ ê²°ê³¼

{all_search_data}

## ìš”êµ¬ì‚¬í•­

ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

1. **í•µì‹¬ ìš”ì•½** (3-5ë¬¸ì¥)
2. **ì£¼ìš” ì‚¬ì‹¤ê³¼ í†µê³„**
3. **ìµœì‹  íŠ¸ë Œë“œ** (2025ë…„ ê¸°ì¤€)
4. **ì „ë¬¸ê°€ ì˜ê²¬ ë° ì¸ìš©**
5. **êµ¬ì²´ì ì¸ ì‚¬ë¡€ ë° ì˜ˆì‹œ**
6. **ë…ìê°€ ì•Œì•„ì•¼ í•  í•µì‹¬ í¬ì¸íŠ¸**

ë³´ê³ ì„œëŠ” í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , ë¸”ë¡œê·¸ ê¸€ ì‘ì„± ì‹œ ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
**ìœ„ì˜ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì„¸ìš”.**
"""

        synthesis_response = llm.invoke(synthesis_prompt)
        synthesized_research = synthesis_response.content

        # 6. ì¶œì²˜ ëª©ë¡ ì¶”ì¶œ
        sources = []
        for result in main_results.get('results', []):
            source = f"[{result['title']}]({result['url']})"
            sources.append(source)

        print(f"âœ… ì¡°ì‚¬ ì™„ë£Œ: {len(sources)}ê°œ ì¶œì²˜ ë°œê²¬")

        return {
            "research_data": synthesized_research,
            "sources": sources,
            "current_stage": "research_complete"
        }

    return research_node
